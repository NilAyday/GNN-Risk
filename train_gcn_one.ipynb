{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "710b2042-116e-4a8f-92f3-74136939e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy import sparse\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919d22b8-92d4-405d-9f30-267db9c11464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708])\n",
      "torch.Size([140])\n",
      "torch.Size([500])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation('cora')\n",
    "data='cora'\n",
    "#splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "#adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data('cora',splitstr)\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(idx_train.shape)\n",
    "print(idx_val.shape)\n",
    "print(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3193118e-5536-4c60-8ac6-d4ea6ebb5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df0ec8-26ee-4028-abf5-d8401f636e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8a630290-eeb5-4007-a441-042e960ada79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features+n+nfeat, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a80b32c3-cfe2-44a4-b5ca-c7d9561e1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size=features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "n=features.shape[0]\n",
    "\n",
    "dropout=0.4\n",
    "\n",
    "#{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'accuracy': 0.792}\n",
    "#{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8180000000000001}\n",
    "#{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8200000000000001}\n",
    "model=my_GCN(feature_size,[512, 256, 128],num_classes,dropout)\n",
    "model=model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.005,weight_decay=0.0005)\n",
    "\n",
    "epochs=100\n",
    "patience=10\n",
    "test=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d6fd08d6-7c9a-4d29-bcb2-2da5855f0b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 train loss:1.968 acc:16.43 | val loss:1.923 acc:17.00\n",
      "Epoch:0002 train loss:1.841 acc:38.57 | val loss:1.849 acc:33.80\n",
      "Epoch:0003 train loss:1.704 acc:63.57 | val loss:1.748 acc:52.40\n",
      "Epoch:0004 train loss:1.491 acc:89.29 | val loss:1.607 acc:66.80\n",
      "Epoch:0005 train loss:1.218 acc:95.71 | val loss:1.422 acc:73.60\n",
      "Epoch:0006 train loss:0.871 acc:96.43 | val loss:1.180 acc:76.80\n",
      "Epoch:0007 train loss:0.541 acc:95.71 | val loss:0.929 acc:78.60\n",
      "Epoch:0008 train loss:0.258 acc:99.29 | val loss:0.802 acc:77.60\n",
      "Epoch:0009 train loss:0.118 acc:99.29 | val loss:0.794 acc:76.80\n",
      "Epoch:0010 train loss:0.060 acc:99.29 | val loss:0.797 acc:77.80\n",
      "Epoch:0011 train loss:0.035 acc:99.29 | val loss:0.806 acc:78.20\n",
      "Epoch:0012 train loss:0.035 acc:99.29 | val loss:0.871 acc:76.20\n",
      "Epoch:0013 train loss:0.016 acc:99.29 | val loss:1.116 acc:72.00\n",
      "Epoch:0014 train loss:0.007 acc:100.00 | val loss:1.350 acc:69.80\n",
      "Epoch:0015 train loss:0.005 acc:100.00 | val loss:1.471 acc:69.00\n",
      "Epoch:0016 train loss:0.010 acc:100.00 | val loss:1.357 acc:71.60\n",
      "Epoch:0017 train loss:0.002 acc:100.00 | val loss:1.409 acc:71.80\n",
      "Epoch:0018 train loss:0.023 acc:98.57 | val loss:1.552 acc:72.20\n",
      "Epoch:0019 train loss:0.019 acc:99.29 | val loss:1.345 acc:74.80\n",
      "Train cost: 4.0862s\n",
      "Load 8th epoch\n",
      "Val acc.:78.1\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test():\n",
    "    #model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "    \n",
    "t_total = time.time()\n",
    "bad_counter = 0\n",
    "best = 999999999\n",
    "best_epoch = 0\n",
    "acc = 0\n",
    "for epoch in range(epochs):\n",
    "    loss_tra,acc_tra = train()\n",
    "    loss_val,acc_val = validate()\n",
    "    if(epoch+1)%1 == 0: \n",
    "        print('Epoch:{:04d}'.format(epoch+1),\n",
    "            'train',\n",
    "            'loss:{:.3f}'.format(loss_tra),\n",
    "            'acc:{:.2f}'.format(acc_tra*100),\n",
    "            '| val',\n",
    "            'loss:{:.3f}'.format(loss_val),\n",
    "            'acc:{:.2f}'.format(acc_val*100))\n",
    "    if loss_val < best:\n",
    "        best = loss_val\n",
    "        best_epoch = epoch\n",
    "        acc = acc_val\n",
    "        #torch.save(model.state_dict(), checkpt_file)\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "    if bad_counter == patience:\n",
    "        break\n",
    "\n",
    "\n",
    "acc = test()[1]\n",
    "\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print('Load {}th epoch'.format(best_epoch))\n",
    "print(\"Val\",\"acc.:{:.1f}\".format(acc*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9badfed2-6e6b-4754-ac92-63aea07c60d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation accuracy: 76.50%\n",
      "Standard deviation of validation accuracy: 1.37%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100  # Set the number of epochs\n",
    "patience = 10  # Set the patience for early stopping\n",
    "Test = True  # Flag for testing after training\n",
    "\n",
    "# Initialize lists to store accuracy for each run\n",
    "val_acc_list = []\n",
    "\n",
    "# Run the training process 10 times\n",
    "for run in range(10):\n",
    "    t_total = time.time()\n",
    "    bad_counter = 0\n",
    "    best = 999999999\n",
    "    best_epoch = 0\n",
    "    acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        loss_tra, acc_tra = train()\n",
    "        loss_val, acc_val = validate()\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            '''\n",
    "            print('Run:{:02d}'.format(run+1),\n",
    "                  'Epoch:{:04d}'.format(epoch+1),\n",
    "                  'train',\n",
    "                  'loss:{:.3f}'.format(loss_tra),\n",
    "                  'acc:{:.2f}'.format(acc_tra * 100),\n",
    "                  '| val',\n",
    "                  'loss:{:.3f}'.format(loss_val),\n",
    "                  'acc:{:.2f}'.format(acc_val * 100))\n",
    "            '''\n",
    "        if loss_val < best:\n",
    "            best = loss_val\n",
    "            best_epoch = epoch\n",
    "            acc = acc_val\n",
    "            # torch.save(model.state_dict(), checkpt_file)\n",
    "            bad_counter = 0\n",
    "        else:\n",
    "            bad_counter += 1\n",
    "\n",
    "        if bad_counter == patience:\n",
    "            break\n",
    "\n",
    "  \n",
    "    acc = test()[1]\n",
    "\n",
    "    val_acc_list.append(acc)\n",
    "\n",
    "    #print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "    #print('Load {}th epoch'.format(best_epoch))\n",
    "    #print(\"Val\", \"acc.:{:.1f}\".format(acc * 100))\n",
    "\n",
    "# Calculate mean and standard deviation of validation accuracy\n",
    "val_acc_array = np.array(val_acc_list)\n",
    "mean_acc = val_acc_array.mean()\n",
    "std_acc = val_acc_array.std()\n",
    "\n",
    "print(\"Mean validation accuracy: {:.2f}%\".format(mean_acc * 100))\n",
    "print(\"Standard deviation of validation accuracy: {:.2f}%\".format(std_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0884a9-3f82-447b-802b-68259b9f724e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
