{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62169ce6-d3ff-486e-8af5-4fc9a5c00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *\n",
    "import pickle\n",
    "import itertools\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ddbba5-f6a5-4367-837b-bcdea631a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708])\n",
      "torch.Size([140])\n",
      "torch.Size([500])\n",
      "torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayday\\Desktop\\Master_Thesis\\experiment\\utils.py:87: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n"
     ]
    }
   ],
   "source": [
    "data='cora'\n",
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation(data)\n",
    "#splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "#adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data(data,splitstr)\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(idx_train.shape)\n",
    "print(idx_val.shape)\n",
    "print(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f516b9ec-672b-4a67-99b1-bbf1323a7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42522538-1af7-4041-894c-3100f095ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=features.shape[0]\n",
    "feature_size=features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e25c24-4159-4e80-92d0-987042226f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee82cd-1ba7-4682-8c7f-2a8ff358a71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf9e80-fea2-443e-93b7-ded05b3e327d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9578-d717-4873-a300-cfd4d01f74b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6477916-3c0a-42a5-925c-7ca5bd3c39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[AH,A,X]\n",
    "results\n",
    "combinations\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'accuracy': 0.792}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32], 'accuracy': 0.778}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'accuracy': 0.786}\n",
    "\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features+n+nfeat, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee6485-6a08-4187-aa06-c698c959e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[H-AH, A, X]\n",
    "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'accuracy': 0.64}\n",
    "results_1\n",
    "intersting all the good acc without hidden layer\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features+n+nfeat, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        #support = torch.cat((torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        #output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "        support = torch.cat((input - torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a677f569-494a-44a2-9504-74dd7b86ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AH+H\n",
    "skip connection\n",
    "results_2\n",
    "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8200000000000001}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'accuracy': 0.81}\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        support = 0.9*torch.mm(adj.to_dense(), input) + 0.1*input\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17ca7a-f77a-4d85-89d2-2eb32b47a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,AH+H]\n",
    "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'accuracy': 0.812}\n",
    "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'accuracy': 0.81}\n",
    "results3\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(nfeat+in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((x,torch.mm(adj.to_dense(), input) + input),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ab8d3f-5aaa-48b6-9a9d-3bc67037110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[AH,X]\n",
    "results4\n",
    "#{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8180000000000001}\n",
    "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8113333333333334, 'std_accuracy': 0.011813363431112911}\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(nfeat+in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((torch.mm(adj.to_dense(), input),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c6a75c7-f2cd-4fc6-8874-0b5b0c373450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7313333333333333\n",
      "0.7566666666666667\n",
      "0.7680000000000001\n",
      "0.7639999999999999\n",
      "0.7566666666666667\n",
      "0.7406666666666667\n",
      "0.7493333333333334\n",
      "0.7493333333333334\n",
      "0.7346666666666666\n",
      "0.7520000000000001\n",
      "0.754\n",
      "0.7646666666666667\n",
      "0.7319999999999999\n",
      "0.7479999999999999\n",
      "0.7346666666666666\n",
      "0.7399999999999999\n",
      "0.7333333333333334\n",
      "0.7593333333333333\n",
      "0.746\n",
      "0.7486666666666667\n",
      "0.7606666666666667\n",
      "0.7426666666666666\n",
      "0.7353333333333333\n",
      "0.754\n",
      "0.6406666666666667\n",
      "0.7706666666666667\n",
      "0.7399999999999999\n",
      "0.7380000000000001\n",
      "0.7160000000000001\n",
      "0.7559999999999999\n",
      "0.7493333333333334\n",
      "0.7513333333333333\n",
      "0.65\n",
      "0.7726666666666667\n",
      "0.7360000000000001\n",
      "0.774\n",
      "0.7046666666666667\n",
      "0.7566666666666667\n",
      "0.738\n",
      "0.766\n",
      "0.6193333333333334\n",
      "0.7786666666666667\n",
      "0.7566666666666667\n",
      "0.7653333333333334\n",
      "0.7473333333333333\n",
      "0.7546666666666667\n",
      "0.7593333333333333\n",
      "0.7466666666666667\n",
      "0.7080000000000001\n",
      "0.7753333333333333\n",
      "0.7760000000000001\n",
      "0.7526666666666667\n",
      "0.7453333333333333\n",
      "0.7326666666666667\n",
      "0.6986666666666667\n",
      "0.7160000000000001\n",
      "0.7186666666666666\n",
      "0.7606666666666667\n",
      "0.7546666666666667\n",
      "0.7360000000000001\n",
      "0.726\n",
      "0.738\n",
      "0.6853333333333333\n",
      "0.7280000000000001\n",
      "0.706\n",
      "0.7613333333333333\n",
      "0.758\n",
      "0.6346666666666666\n",
      "0.7193333333333333\n",
      "0.742\n",
      "0.7306666666666667\n",
      "0.722\n",
      "0.73\n",
      "0.7693333333333333\n",
      "0.7706666666666667\n",
      "0.7646666666666667\n",
      "0.7313333333333333\n",
      "0.7559999999999999\n",
      "0.7393333333333333\n",
      "0.7366666666666667\n",
      "0.7273333333333333\n",
      "0.774\n",
      "0.738\n",
      "0.7746666666666666\n",
      "0.7553333333333333\n",
      "0.7446666666666667\n",
      "0.7479999999999999\n",
      "0.7366666666666667\n",
      "0.7326666666666667\n",
      "0.7680000000000001\n",
      "0.762\n",
      "0.7513333333333333\n",
      "0.7293333333333333\n",
      "0.7239999999999999\n",
      "0.7393333333333333\n",
      "0.7533333333333333\n",
      "0.714\n",
      "0.762\n",
      "0.7566666666666667\n",
      "0.7680000000000001\n",
      "0.7653333333333334\n",
      "0.7706666666666667\n",
      "0.742\n",
      "0.7666666666666666\n",
      "0.7153333333333333\n",
      "0.758\n",
      "0.7646666666666667\n",
      "0.7733333333333334\n",
      "0.7520000000000001\n",
      "0.7399999999999999\n",
      "0.7533333333333333\n",
      "0.7613333333333333\n",
      "0.7200000000000001\n",
      "0.7653333333333334\n",
      "0.7646666666666667\n",
      "0.7646666666666667\n",
      "0.75\n",
      "0.7680000000000001\n",
      "0.7613333333333333\n",
      "0.774\n",
      "0.7206666666666667\n",
      "0.7766666666666667\n",
      "0.7526666666666667\n",
      "0.7506666666666666\n",
      "0.7280000000000001\n",
      "0.7533333333333333\n",
      "0.7693333333333333\n",
      "0.7559999999999999\n",
      "0.7213333333333333\n",
      "0.7713333333333333\n",
      "0.7593333333333333\n",
      "0.7639999999999999\n",
      "0.39200000000000007\n",
      "0.7573333333333334\n",
      "0.7686666666666667\n",
      "0.7600000000000001\n",
      "0.7213333333333333\n",
      "0.7706666666666667\n",
      "0.7726666666666667\n",
      "0.774\n",
      "0.6626666666666666\n",
      "0.742\n",
      "0.762\n",
      "0.7713333333333333\n",
      "0.7033333333333333\n",
      "0.7633333333333333\n",
      "0.7639999999999999\n",
      "0.758\n",
      "0.7566666666666667\n",
      "0.7653333333333334\n",
      "0.7520000000000001\n",
      "0.7466666666666667\n",
      "0.7020000000000001\n",
      "0.7653333333333334\n",
      "0.7533333333333333\n",
      "0.7606666666666667\n",
      "0.7173333333333334\n",
      "0.774\n",
      "0.7346666666666666\n",
      "0.7646666666666667\n",
      "0.7106666666666666\n",
      "0.7613333333333333\n",
      "0.7639999999999999\n",
      "0.7673333333333333\n",
      "0.7326666666666667\n",
      "0.7553333333333333\n",
      "0.7366666666666667\n",
      "0.7626666666666667\n",
      "0.7226666666666667\n",
      "0.77\n",
      "0.758\n",
      "0.7586666666666666\n",
      "0.7280000000000001\n",
      "0.766\n",
      "0.7593333333333333\n",
      "0.7546666666666667\n",
      "0.7146666666666667\n",
      "0.7706666666666667\n",
      "0.758\n",
      "0.7653333333333334\n",
      "0.7453333333333333\n",
      "0.7513333333333333\n",
      "0.7319999999999999\n",
      "0.758\n",
      "0.7226666666666667\n",
      "0.7726666666666667\n",
      "0.7473333333333333\n",
      "0.7513333333333333\n",
      "0.7573333333333334\n",
      "0.7366666666666667\n",
      "0.762\n",
      "0.766\n",
      "0.6973333333333334\n",
      "0.7666666666666666\n",
      "0.7639999999999999\n",
      "0.7646666666666667\n",
      "0.7399999999999999\n",
      "0.7766666666666667\n",
      "0.7513333333333333\n",
      "0.7706666666666667\n",
      "0.6893333333333334\n",
      "0.7593333333333333\n",
      "0.7633333333333333\n",
      "0.7586666666666666\n",
      "0.7346666666666666\n",
      "0.7646666666666667\n",
      "0.762\n",
      "0.758\n",
      "0.7086666666666668\n",
      "0.7653333333333334\n",
      "0.7646666666666667\n",
      "0.7673333333333333\n",
      "0.73\n",
      "0.7566666666666667\n",
      "0.7626666666666667\n",
      "0.77\n",
      "0.6586666666666666\n",
      "0.762\n",
      "0.7626666666666667\n",
      "0.7546666666666667\n",
      "0.5293333333333333\n",
      "0.7493333333333334\n",
      "0.7440000000000001\n",
      "0.7626666666666667\n",
      "0.6766666666666667\n",
      "0.77\n",
      "0.7753333333333333\n",
      "0.7473333333333333\n",
      "0.5313333333333333\n",
      "0.7393333333333333\n",
      "0.7573333333333334\n",
      "0.7626666666666667\n",
      "0.67\n",
      "0.7666666666666666\n",
      "0.7666666666666666\n",
      "0.7566666666666667\n",
      "0.7053333333333334\n",
      "0.7346666666666666\n",
      "0.7633333333333333\n",
      "0.7593333333333333\n",
      "0.6966666666666668\n",
      "0.7553333333333333\n",
      "0.7666666666666666\n",
      "0.7680000000000001\n",
      "0.754\n",
      "0.7553333333333333\n",
      "0.7593333333333333\n",
      "0.7440000000000001\n",
      "0.6806666666666668\n",
      "0.7606666666666667\n",
      "0.7573333333333334\n",
      "0.7626666666666667\n",
      "0.7293333333333333\n",
      "0.7613333333333333\n",
      "0.758\n",
      "0.7673333333333333\n",
      "0.6806666666666668\n",
      "0.7566666666666667\n",
      "0.7546666666666667\n",
      "0.7593333333333333\n",
      "0.7426666666666666\n",
      "0.7626666666666667\n",
      "0.7513333333333333\n",
      "0.762\n",
      "0.7033333333333333\n",
      "0.7566666666666667\n",
      "0.7613333333333333\n",
      "0.7719999999999999\n",
      "0.7413333333333334\n",
      "0.7526666666666667\n",
      "0.7453333333333333\n",
      "0.7593333333333333\n",
      "0.6933333333333334\n",
      "0.7693333333333333\n",
      "0.7573333333333334\n",
      "0.7639999999999999\n",
      "0.7493333333333334\n",
      "0.734\n",
      "0.7573333333333334\n",
      "0.7586666666666666\n",
      "0.6833333333333332\n",
      "0.7639999999999999\n",
      "0.7566666666666667\n",
      "0.7713333333333333\n",
      "0.7479999999999999\n",
      "0.7646666666666667\n",
      "0.7553333333333333\n",
      "0.7506666666666666\n",
      "0.32\n",
      "0.722\n",
      "0.7586666666666666\n",
      "0.7666666666666666\n",
      "0.556\n",
      "0.758\n",
      "0.7666666666666666\n",
      "0.7653333333333334\n",
      "0.24333333333333337\n",
      "0.7266666666666666\n",
      "0.758\n",
      "0.7713333333333333\n",
      "0.5886666666666667\n",
      "0.7406666666666667\n",
      "0.77\n",
      "0.7686666666666667\n",
      "0.24466666666666667\n",
      "0.7266666666666666\n",
      "0.7566666666666667\n",
      "0.7633333333333333\n",
      "0.5840000000000001\n",
      "0.7513333333333333\n",
      "0.7680000000000001\n",
      "0.7706666666666667\n",
      "0.18066666666666667\n",
      "0.5226666666666666\n",
      "0.6473333333333334\n",
      "0.758\n",
      "0.21866666666666668\n",
      "0.6913333333333335\n",
      "0.7666666666666666\n",
      "0.758\n",
      "0.17133333333333334\n",
      "0.534\n",
      "0.6633333333333334\n",
      "0.7600000000000001\n",
      "0.19200000000000003\n",
      "0.7393333333333333\n",
      "0.7586666666666666\n",
      "0.7613333333333333\n",
      "0.16333333333333333\n",
      "0.5526666666666666\n",
      "0.6533333333333333\n",
      "0.7673333333333333\n",
      "0.17666666666666667\n",
      "0.7319999999999999\n",
      "0.7606666666666667\n",
      "0.7639999999999999\n",
      "0.3226666666666667\n",
      "0.7373333333333333\n",
      "0.7533333333333333\n",
      "0.7633333333333333\n",
      "0.6606666666666667\n",
      "0.7520000000000001\n",
      "0.7673333333333333\n",
      "0.766\n",
      "0.25266666666666665\n",
      "0.7386666666666667\n",
      "0.7493333333333334\n",
      "0.7633333333333333\n",
      "0.608\n",
      "0.754\n",
      "0.7520000000000001\n",
      "0.7633333333333333\n",
      "0.2793333333333334\n",
      "0.7186666666666666\n",
      "0.7653333333333334\n",
      "0.7613333333333333\n",
      "0.6626666666666666\n",
      "0.758\n",
      "0.7646666666666667\n",
      "0.7680000000000001\n",
      "0.2006666666666667\n",
      "0.7046666666666667\n",
      "0.762\n",
      "0.758\n",
      "0.44599999999999995\n",
      "0.7606666666666667\n",
      "0.7693333333333333\n",
      "0.766\n",
      "0.2773333333333334\n",
      "0.7013333333333334\n",
      "0.7673333333333333\n",
      "0.7626666666666667\n",
      "0.4993333333333334\n",
      "0.7406666666666667\n",
      "0.766\n",
      "0.7733333333333334\n",
      "0.24666666666666667\n",
      "0.7053333333333333\n",
      "0.7566666666666667\n",
      "0.758\n",
      "0.4186666666666667\n",
      "0.7646666666666667\n",
      "0.774\n",
      "0.7666666666666666\n",
      "Hyperparameters and accuracies sorted by mean accuracy:\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7766666666666667, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7766666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7760000000000001, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7753333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7753333333333333, 'std_accuracy': 0.009428090415820642}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.774, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.774, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.774, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.774, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.774, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.774, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7733333333333334, 'std_accuracy': 0.010498677165349092}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7733333333333334, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7726666666666667, 'std_accuracy': 0.010370899457402707}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7726666666666667, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7726666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7719999999999999, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.016357125528513743}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.009843215373488942}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.77, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.77, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.77, 'std_accuracy': 0.002828427124746193}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.77, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7693333333333333, 'std_accuracy': 0.011115554667022054}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7693333333333333, 'std_accuracy': 0.011585431464655188}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7693333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7693333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7686666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7686666666666667, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.011430952132988175}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.007483314773547889}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.011775681155103806}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.010370899457402707}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.007363574011458181}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.766, 'std_accuracy': 0.011430952132988174}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.766, 'std_accuracy': 0.013952299690970912}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.766, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.766, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.766, 'std_accuracy': 0.005656854249492385}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.766, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.01236482466066095}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.007363574011458181}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.0131993265821489}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.016996731711975962}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.012036980056845203}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.009285592184789422}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.011430952132988175}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.009428090415820642}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.011585431464655188}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.01472714802291636}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.010498677165349092}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.762, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.762, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.762, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.762, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.762, 'std_accuracy': 0.007483314773547889}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.762, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.762, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.762, 'std_accuracy': 0.015748015748023637}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.020805982045769663}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.01791337179005922}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.012256517540566834}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.017152907107024825}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7600000000000001, 'std_accuracy': 0.011775681155103806}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7600000000000001, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.01407914138796193}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.009843215373488944}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7586666666666666, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7586666666666666, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7586666666666666, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7586666666666666, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7586666666666666, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.758, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.758, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.013063945294843629}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.758, 'std_accuracy': 0.011775681155103806}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.758, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.758, 'std_accuracy': 0.011430952132988175}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.758, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.758, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.758, 'std_accuracy': 0.008485281374238578}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.758, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.758, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.010498677165349092}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.022291004663067337}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.011115554667022055}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.019136933459209783}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7566666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7559999999999999, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7559999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7559999999999999, 'std_accuracy': 0.0056568542494923844}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.009428090415820642}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.009428090415820642}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.01236482466066095}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7546666666666667, 'std_accuracy': 0.010624918300339495}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7546666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7546666666666667, 'std_accuracy': 0.016759740119968728}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7546666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7546666666666667, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.754, 'std_accuracy': 0.016329931618554536}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.754, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.754, 'std_accuracy': 0.013063945294843629}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.754, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.016357125528513743}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.026849374087469714}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.013597385369580772}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.01388844443733312}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.013299958228840014}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7520000000000001, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7520000000000001, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7520000000000001, 'std_accuracy': 0.02196967607104546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7520000000000001, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7520000000000001, 'std_accuracy': 0.007483314773547889}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.01878533707147384}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.021746008573733475}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.015434449203720314}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7506666666666666, 'std_accuracy': 0.011469767022723513}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7506666666666666, 'std_accuracy': 0.020548046676563275}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.75, 'std_accuracy': 0.013366625103842294}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.02858126814696805}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.020417857108151423}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.00805536398239639}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7486666666666667, 'std_accuracy': 0.01791337179005922}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7479999999999999, 'std_accuracy': 0.016083117442419772}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7479999999999999, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7479999999999999, 'std_accuracy': 0.021228911104120896}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7473333333333333, 'std_accuracy': 0.03116978594016259}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.7473333333333333, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7473333333333333, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7466666666666667, 'std_accuracy': 0.020677416559027783}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7466666666666667, 'std_accuracy': 0.012036980056845203}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.746, 'std_accuracy': 0.018184242262647823}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7453333333333333, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7453333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7453333333333333, 'std_accuracy': 0.016357125528513743}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7446666666666667, 'std_accuracy': 0.016759740119968728}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7440000000000001, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7440000000000001, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7426666666666666, 'std_accuracy': 0.016357125528513743}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7426666666666666, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.742, 'std_accuracy': 0.015748015748023637}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.742, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.742, 'std_accuracy': 0.030506829836393443}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7413333333333334, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7406666666666667, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7406666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7406666666666667, 'std_accuracy': 0.023113247764479643}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7399999999999999, 'std_accuracy': 0.019866219234335136}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.7399999999999999, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7399999999999999, 'std_accuracy': 0.00748331477354789}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7399999999999999, 'std_accuracy': 0.005656854249492385}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.023570226039551605}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7386666666666667, 'std_accuracy': 0.012684198393626975}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7380000000000001, 'std_accuracy': 0.02833137248116768}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.738, 'std_accuracy': 0.00979795897113272}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.738, 'std_accuracy': 0.013366625103842294}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.738, 'std_accuracy': 0.0065319726474218145}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7373333333333333, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7366666666666667, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7366666666666667, 'std_accuracy': 0.014817407180595259}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7366666666666667, 'std_accuracy': 0.03193048003954144}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7366666666666667, 'std_accuracy': 0.020417857108151423}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.7360000000000001, 'std_accuracy': 0.023036203390894683}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7360000000000001, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7353333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7346666666666666, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7346666666666666, 'std_accuracy': 0.02604269997949945}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7346666666666666, 'std_accuracy': 0.021561282171728327}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7346666666666666, 'std_accuracy': 0.01651934892448517}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7346666666666666, 'std_accuracy': 0.0182086670449969}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.734, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7333333333333334, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7326666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7326666666666667, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7326666666666667, 'std_accuracy': 0.01995550606279437}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7319999999999999, 'std_accuracy': 0.01704894913672591}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7319999999999999, 'std_accuracy': 0.013063945294843629}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7319999999999999, 'std_accuracy': 0.01925270543759155}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7313333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7313333333333333, 'std_accuracy': 0.017307673314329575}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7306666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.73, 'std_accuracy': 0.002828427124746193}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.73, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7293333333333333, 'std_accuracy': 0.014267289706021811}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7293333333333333, 'std_accuracy': 0.01236482466066095}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7280000000000001, 'std_accuracy': 0.033980386499665734}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7280000000000001, 'std_accuracy': 0.03278210894171797}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7280000000000001, 'std_accuracy': 0.02135415650406259}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7273333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7266666666666666, 'std_accuracy': 0.011813363431112911}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7266666666666666, 'std_accuracy': 0.01407914138796193}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.726, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7239999999999999, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7226666666666667, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7226666666666667, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.722, 'std_accuracy': 0.02046134567096371}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.722, 'std_accuracy': 0.039597979746446646}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7213333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7213333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7206666666666667, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7200000000000001, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7193333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7186666666666666, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7186666666666666, 'std_accuracy': 0.024944382578492925}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7173333333333334, 'std_accuracy': 0.021060758665241732}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7160000000000001, 'std_accuracy': 0.028284271247461874}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7160000000000001, 'std_accuracy': 0.03115552385479444}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7153333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7146666666666667, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.714, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7106666666666666, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.7086666666666668, 'std_accuracy': 0.007717224601860106}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7080000000000001, 'std_accuracy': 0.011430952132988123}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.706, 'std_accuracy': 0.017281975195754258}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7053333333333334, 'std_accuracy': 0.08224083873329331}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.7053333333333333, 'std_accuracy': 0.0037712361663282045}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7046666666666667, 'std_accuracy': 0.03641733408999375}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.7046666666666667, 'std_accuracy': 0.00821921867062526}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7033333333333333, 'std_accuracy': 0.004109609335312607}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.7033333333333333, 'std_accuracy': 0.003399346342395142}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.7020000000000001, 'std_accuracy': 0.007118052168020829}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.7013333333333334, 'std_accuracy': 0.014079141387961881}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.6986666666666667, 'std_accuracy': 0.029044027881055926}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6973333333333334, 'std_accuracy': 0.011585431464655148}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6966666666666668, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6933333333333334, 'std_accuracy': 0.01543444920372028}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.6913333333333335, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6893333333333334, 'std_accuracy': 0.013888444437333117}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.6853333333333333, 'std_accuracy': 0.031041191271527487}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6833333333333332, 'std_accuracy': 0.01715290710702478}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6806666666666668, 'std_accuracy': 0.015860503004493775}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6806666666666668, 'std_accuracy': 0.011813363431112911}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6766666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.67, 'std_accuracy': 0.03676955262170051}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 64], 'mean_accuracy': 0.6633333333333334, 'std_accuracy': 0.027824849006278966}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.6626666666666666, 'std_accuracy': 0.021249836600678987}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.6626666666666666, 'std_accuracy': 0.028767265347188584}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.6606666666666667, 'std_accuracy': 0.026549743668986527}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6586666666666666, 'std_accuracy': 0.022881336402307374}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 64], 'mean_accuracy': 0.6533333333333333, 'std_accuracy': 0.018354533197248286}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.65, 'std_accuracy': 0.052990565197967084}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 64], 'mean_accuracy': 0.6473333333333334, 'std_accuracy': 0.03303869784897034}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6406666666666667, 'std_accuracy': 0.045323528351422795}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.6346666666666666, 'std_accuracy': 0.0549019327731021}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6193333333333334, 'std_accuracy': 0.044010099850930684}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.608, 'std_accuracy': 0.03490940656422944}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5886666666666667, 'std_accuracy': 0.06796731240497565}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5840000000000001, 'std_accuracy': 0.046733285782191686}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.556, 'std_accuracy': 0.07812809993849844}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64], 'mean_accuracy': 0.5526666666666666, 'std_accuracy': 0.07570703768841806}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64], 'mean_accuracy': 0.534, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5313333333333333, 'std_accuracy': 0.23062427356103596}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5293333333333333, 'std_accuracy': 0.2556890472603175}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64], 'mean_accuracy': 0.5226666666666666, 'std_accuracy': 0.054020572213021034}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.4993333333333334, 'std_accuracy': 0.07193206671730087}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.44599999999999995, 'std_accuracy': 0.02438578821089584}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.4186666666666667, 'std_accuracy': 0.08317585119625903}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.39200000000000007, 'std_accuracy': 0.19706513305672993}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.3226666666666667, 'std_accuracy': 0.06671997868371629}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.32, 'std_accuracy': 0.06933974329343887}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.2793333333333334, 'std_accuracy': 0.046657141885127186}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.2773333333333334, 'std_accuracy': 0.08246750201678774}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.25266666666666665, 'std_accuracy': 0.017987650084309394}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.24666666666666667, 'std_accuracy': 0.02362672686222581}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.24466666666666667, 'std_accuracy': 0.09669654710599662}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.24333333333333337, 'std_accuracy': 0.10708667309966985}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.21866666666666668, 'std_accuracy': 0.016110727964792765}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.2006666666666667, 'std_accuracy': 0.02054804667656325}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.19200000000000003, 'std_accuracy': 0.03581433604950211}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.18066666666666667, 'std_accuracy': 0.09721911106133174}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.17666666666666667, 'std_accuracy': 0.01472714802291635}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.17133333333333334, 'std_accuracy': 0.01995550606279436}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.16333333333333333, 'std_accuracy': 0.05389702115042063}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define your train, validate, and test functions\n",
    "def train(model, optimizer, features, adj, labels, idx_train):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(), acc_train.item()\n",
    "\n",
    "def validate(model, features, adj, labels, idx_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(), acc_val.item()\n",
    "\n",
    "def test(model, features, adj, labels, idx_test, checkpt_file):\n",
    "    model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(), acc_test.item()\n",
    "\n",
    "def load_previous_results(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return []\n",
    "\n",
    "def save_results(file_path, results):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "# Hyperparameters\n",
    "nfeat = features.shape[1]\n",
    "nclass = num_classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hyperparams = {\n",
    "    'lr': [0.05, 0.01, 0.005, 0.001],\n",
    "    'weight_decay': [5e-4, 5e-3, 1e-4, 1e-3],\n",
    "    'dropout': [0.5, 0.3, 0.4],\n",
    "    'nhid_list': [[], [64],[64,64],[256, 512], [16, 32, 16], [64, 128, 64], [512, 1024, 512], [128, 512, 128]]\n",
    "}\n",
    "\n",
    "# File paths for saving results and combinations\n",
    "results_file_path = 'auto_results/results.pkl'\n",
    "combinations_file_path = 'auto_results/combinations.pkl'\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# To store already run combinations\n",
    "run_combinations = set()\n",
    "\n",
    "# Load previously run combinations if available\n",
    "results = load_previous_results(results_file_path)\n",
    "for result in results:\n",
    "     run_combinations.add((result['lr'], result['weight_decay'], result['dropout'], tuple(result['nhid_list'])))\n",
    "\n",
    "for lr, weight_decay, dropout, nhid_list in itertools.product(\n",
    "    hyperparams['lr'], hyperparams['weight_decay'], hyperparams['dropout'], hyperparams['nhid_list']\n",
    "):\n",
    "    combination = (lr, weight_decay, dropout, tuple(nhid_list))\n",
    "    \n",
    "    if combination in run_combinations:\n",
    "        print(f\"Skipping already run combination: {combination}\")\n",
    "        continue\n",
    "    \n",
    "    run_combinations.add(combination)\n",
    "    \n",
    "    accuracies = []\n",
    "    for _ in range(3):  # Run each combination 3 times\n",
    "        model = my_GCN(nfeat, nhid_list, nclass, dropout)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        epochs = 100\n",
    "        patience = 10\n",
    "        best = 999999999\n",
    "        best_epoch = 0\n",
    "        acc = 0\n",
    "        t_total = time.time()\n",
    "        bad_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_tra, acc_tra = train(model, optimizer, features, adj, labels, idx_train)\n",
    "            loss_val, acc_val = validate(model, features, adj, labels, idx_val)\n",
    "            if (epoch+1) % 1 == 0: \n",
    "                pass  # You can print progress here if needed\n",
    "\n",
    "            if loss_val < best:\n",
    "                best = loss_val\n",
    "                best_epoch = epoch\n",
    "                acc = acc_val\n",
    "                bad_counter = 0\n",
    "            else:\n",
    "                bad_counter += 1\n",
    "\n",
    "            if bad_counter == patience:\n",
    "                break\n",
    "\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies)\n",
    "    print(mean_acc)\n",
    "    \n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'dropout': dropout,\n",
    "        'nhid_list': nhid_list,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc\n",
    "    })\n",
    "\n",
    "# Sort results by mean accuracy in descending order\n",
    "results = sorted(results, key=lambda x: x['mean_accuracy'], reverse=True)\n",
    "\n",
    "print(\"Hyperparameters and accuracies sorted by mean accuracy:\")\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Save results and run_combinations for future use\n",
    "save_results(results_file_path, results)\n",
    "save_results(combinations_file_path, list(run_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f28a6-47bb-4aae-a7b3-c7b941a071e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d24e8-ef33-4e6e-b28c-9a645ce83d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
