{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b3b70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342676d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3dafa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708])\n",
      "torch.Size([140])\n",
      "torch.Size([500])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation('cora')\n",
    "data='cora'\n",
    "#splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "#adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data('cora',splitstr)\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(idx_train.shape)\n",
    "print(idx_val.shape)\n",
    "print(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2dbd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfcb0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size=features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "hidden_dim=16\n",
    "dropout=0.5\n",
    "model=GCN(feature_size,hidden_dim,num_classes,dropout)\n",
    "model=model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)\n",
    "\n",
    "epochs=100\n",
    "patience=10\n",
    "test=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74ad2d-db4d-484a-8d42-0f70e1a6bec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf697f-0d71-47c7-a2c8-0cfcdab69a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bd930-acc7-4362-820c-e37bd0ae0054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3749f70-40c0-434f-b6dd-212227bc6270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ef09b6d-839a-448e-82a6-8d85bf4a7fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 train loss:1.961 acc:15.00 | val loss:1.949 acc:7.00\n",
      "Epoch:0002 train loss:1.952 acc:15.00 | val loss:1.947 acc:7.40\n",
      "Epoch:0003 train loss:1.955 acc:11.43 | val loss:1.945 acc:7.60\n",
      "Epoch:0004 train loss:1.949 acc:14.29 | val loss:1.944 acc:7.60\n",
      "Epoch:0005 train loss:1.943 acc:14.29 | val loss:1.943 acc:7.60\n",
      "Epoch:0006 train loss:1.942 acc:17.86 | val loss:1.941 acc:7.80\n",
      "Epoch:0007 train loss:1.931 acc:19.29 | val loss:1.939 acc:8.60\n",
      "Epoch:0008 train loss:1.934 acc:20.00 | val loss:1.937 acc:10.40\n",
      "Epoch:0009 train loss:1.927 acc:20.71 | val loss:1.934 acc:12.00\n",
      "Epoch:0010 train loss:1.913 acc:27.86 | val loss:1.931 acc:15.40\n",
      "Epoch:0011 train loss:1.905 acc:32.86 | val loss:1.929 acc:18.80\n",
      "Epoch:0012 train loss:1.902 acc:36.43 | val loss:1.926 acc:22.00\n",
      "Epoch:0013 train loss:1.902 acc:34.29 | val loss:1.923 acc:24.20\n",
      "Epoch:0014 train loss:1.894 acc:38.57 | val loss:1.921 acc:23.80\n",
      "Epoch:0015 train loss:1.887 acc:42.14 | val loss:1.918 acc:24.80\n",
      "Epoch:0016 train loss:1.882 acc:42.14 | val loss:1.914 acc:29.60\n",
      "Epoch:0017 train loss:1.869 acc:47.86 | val loss:1.911 acc:35.20\n",
      "Epoch:0018 train loss:1.871 acc:48.57 | val loss:1.907 acc:37.20\n",
      "Epoch:0019 train loss:1.853 acc:57.14 | val loss:1.902 acc:40.20\n",
      "Epoch:0020 train loss:1.846 acc:55.71 | val loss:1.898 acc:42.40\n",
      "Epoch:0021 train loss:1.830 acc:60.00 | val loss:1.892 acc:43.40\n",
      "Epoch:0022 train loss:1.839 acc:57.86 | val loss:1.887 acc:43.60\n",
      "Epoch:0023 train loss:1.822 acc:60.00 | val loss:1.882 acc:44.80\n",
      "Epoch:0024 train loss:1.816 acc:60.71 | val loss:1.875 acc:45.60\n",
      "Epoch:0025 train loss:1.790 acc:65.71 | val loss:1.869 acc:47.00\n",
      "Epoch:0026 train loss:1.790 acc:64.29 | val loss:1.862 acc:49.60\n",
      "Epoch:0027 train loss:1.766 acc:68.57 | val loss:1.855 acc:50.40\n",
      "Epoch:0028 train loss:1.776 acc:61.43 | val loss:1.848 acc:51.60\n",
      "Epoch:0029 train loss:1.758 acc:62.86 | val loss:1.840 acc:54.40\n",
      "Epoch:0030 train loss:1.732 acc:72.86 | val loss:1.832 acc:55.80\n",
      "Epoch:0031 train loss:1.725 acc:69.29 | val loss:1.824 acc:57.60\n",
      "Epoch:0032 train loss:1.697 acc:74.29 | val loss:1.815 acc:59.40\n",
      "Epoch:0033 train loss:1.705 acc:70.00 | val loss:1.806 acc:60.40\n",
      "Epoch:0034 train loss:1.694 acc:73.57 | val loss:1.797 acc:62.80\n",
      "Epoch:0035 train loss:1.671 acc:72.14 | val loss:1.788 acc:63.80\n",
      "Epoch:0036 train loss:1.656 acc:75.71 | val loss:1.779 acc:64.60\n",
      "Epoch:0037 train loss:1.649 acc:73.57 | val loss:1.771 acc:64.60\n",
      "Epoch:0038 train loss:1.627 acc:72.86 | val loss:1.762 acc:64.20\n",
      "Epoch:0039 train loss:1.616 acc:76.43 | val loss:1.754 acc:65.20\n",
      "Epoch:0040 train loss:1.600 acc:71.43 | val loss:1.745 acc:65.40\n",
      "Epoch:0041 train loss:1.568 acc:84.29 | val loss:1.737 acc:66.00\n",
      "Epoch:0042 train loss:1.581 acc:80.71 | val loss:1.728 acc:65.60\n",
      "Epoch:0043 train loss:1.530 acc:79.29 | val loss:1.717 acc:66.20\n",
      "Epoch:0044 train loss:1.500 acc:79.29 | val loss:1.706 acc:66.00\n",
      "Epoch:0045 train loss:1.474 acc:82.14 | val loss:1.694 acc:67.00\n",
      "Epoch:0046 train loss:1.466 acc:87.14 | val loss:1.682 acc:67.60\n",
      "Epoch:0047 train loss:1.448 acc:85.71 | val loss:1.669 acc:67.80\n",
      "Epoch:0048 train loss:1.454 acc:77.14 | val loss:1.656 acc:67.80\n",
      "Epoch:0049 train loss:1.388 acc:84.29 | val loss:1.642 acc:68.80\n",
      "Epoch:0050 train loss:1.417 acc:80.00 | val loss:1.629 acc:69.00\n",
      "Epoch:0051 train loss:1.383 acc:80.71 | val loss:1.616 acc:69.40\n",
      "Epoch:0052 train loss:1.390 acc:77.14 | val loss:1.603 acc:69.40\n",
      "Epoch:0053 train loss:1.314 acc:85.00 | val loss:1.590 acc:70.00\n",
      "Epoch:0054 train loss:1.332 acc:84.29 | val loss:1.576 acc:71.00\n",
      "Epoch:0055 train loss:1.309 acc:77.14 | val loss:1.561 acc:72.00\n",
      "Epoch:0056 train loss:1.292 acc:86.43 | val loss:1.547 acc:72.20\n",
      "Epoch:0057 train loss:1.250 acc:88.57 | val loss:1.533 acc:72.60\n",
      "Epoch:0058 train loss:1.246 acc:88.57 | val loss:1.520 acc:72.80\n",
      "Epoch:0059 train loss:1.279 acc:82.14 | val loss:1.506 acc:73.20\n",
      "Epoch:0060 train loss:1.217 acc:83.57 | val loss:1.493 acc:73.40\n",
      "Epoch:0061 train loss:1.175 acc:87.86 | val loss:1.479 acc:73.60\n",
      "Epoch:0062 train loss:1.175 acc:83.57 | val loss:1.467 acc:74.20\n",
      "Epoch:0063 train loss:1.165 acc:84.29 | val loss:1.455 acc:74.20\n",
      "Epoch:0064 train loss:1.116 acc:88.57 | val loss:1.444 acc:74.20\n",
      "Epoch:0065 train loss:1.108 acc:86.43 | val loss:1.432 acc:74.20\n",
      "Epoch:0066 train loss:1.124 acc:86.43 | val loss:1.420 acc:74.00\n",
      "Epoch:0067 train loss:1.091 acc:88.57 | val loss:1.408 acc:74.00\n",
      "Epoch:0068 train loss:1.088 acc:88.57 | val loss:1.397 acc:74.20\n",
      "Epoch:0069 train loss:1.032 acc:85.00 | val loss:1.384 acc:74.20\n",
      "Epoch:0070 train loss:0.989 acc:87.86 | val loss:1.371 acc:74.20\n",
      "Epoch:0071 train loss:1.021 acc:87.86 | val loss:1.357 acc:74.60\n",
      "Epoch:0072 train loss:1.008 acc:85.00 | val loss:1.343 acc:75.40\n",
      "Epoch:0073 train loss:0.993 acc:87.14 | val loss:1.329 acc:75.80\n",
      "Epoch:0074 train loss:0.927 acc:91.43 | val loss:1.316 acc:75.60\n",
      "Epoch:0075 train loss:0.964 acc:90.00 | val loss:1.303 acc:75.80\n",
      "Epoch:0076 train loss:0.936 acc:88.57 | val loss:1.291 acc:76.40\n",
      "Epoch:0077 train loss:0.934 acc:90.71 | val loss:1.280 acc:76.40\n",
      "Epoch:0078 train loss:0.939 acc:93.57 | val loss:1.269 acc:76.40\n",
      "Epoch:0079 train loss:0.909 acc:87.86 | val loss:1.259 acc:76.40\n",
      "Epoch:0080 train loss:0.919 acc:90.00 | val loss:1.251 acc:76.00\n",
      "Epoch:0081 train loss:0.857 acc:92.14 | val loss:1.243 acc:76.00\n",
      "Epoch:0082 train loss:0.882 acc:87.86 | val loss:1.235 acc:76.00\n",
      "Epoch:0083 train loss:0.827 acc:91.43 | val loss:1.227 acc:76.40\n",
      "Epoch:0084 train loss:0.846 acc:90.71 | val loss:1.220 acc:75.80\n",
      "Epoch:0085 train loss:0.833 acc:89.29 | val loss:1.210 acc:75.60\n",
      "Epoch:0086 train loss:0.764 acc:89.29 | val loss:1.201 acc:75.80\n",
      "Epoch:0087 train loss:0.802 acc:87.14 | val loss:1.195 acc:76.20\n",
      "Epoch:0088 train loss:0.785 acc:89.29 | val loss:1.186 acc:76.00\n",
      "Epoch:0089 train loss:0.765 acc:94.29 | val loss:1.176 acc:76.40\n",
      "Epoch:0090 train loss:0.745 acc:92.86 | val loss:1.166 acc:76.40\n",
      "Epoch:0091 train loss:0.760 acc:93.57 | val loss:1.155 acc:76.40\n",
      "Epoch:0092 train loss:0.745 acc:92.86 | val loss:1.144 acc:76.00\n",
      "Epoch:0093 train loss:0.702 acc:93.57 | val loss:1.134 acc:76.60\n",
      "Epoch:0094 train loss:0.736 acc:89.29 | val loss:1.127 acc:77.00\n",
      "Epoch:0095 train loss:0.692 acc:95.00 | val loss:1.122 acc:76.60\n",
      "Epoch:0096 train loss:0.720 acc:90.00 | val loss:1.117 acc:76.60\n",
      "Epoch:0097 train loss:0.715 acc:90.00 | val loss:1.109 acc:77.00\n",
      "Epoch:0098 train loss:0.676 acc:95.00 | val loss:1.102 acc:77.40\n",
      "Epoch:0099 train loss:0.674 acc:94.29 | val loss:1.095 acc:77.40\n",
      "Epoch:0100 train loss:0.694 acc:94.29 | val loss:1.090 acc:77.40\n",
      "Train cost: 1.1665s\n",
      "Load 99th epoch\n",
      "Val acc.:79.4\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test():\n",
    "    #model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "    \n",
    "t_total = time.time()\n",
    "bad_counter = 0\n",
    "best = 999999999\n",
    "best_epoch = 0\n",
    "acc = 0\n",
    "for epoch in range(epochs):\n",
    "    loss_tra,acc_tra = train()\n",
    "    loss_val,acc_val = validate()\n",
    "    if(epoch+1)%1 == 0: \n",
    "        print('Epoch:{:04d}'.format(epoch+1),\n",
    "            'train',\n",
    "            'loss:{:.3f}'.format(loss_tra),\n",
    "            'acc:{:.2f}'.format(acc_tra*100),\n",
    "            '| val',\n",
    "            'loss:{:.3f}'.format(loss_val),\n",
    "            'acc:{:.2f}'.format(acc_val*100))\n",
    "    if loss_val < best:\n",
    "        best = loss_val\n",
    "        best_epoch = epoch\n",
    "        acc = acc_val\n",
    "        #torch.save(model.state_dict(), checkpt_file)\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "    if bad_counter == patience:\n",
    "        break\n",
    "\n",
    "if test:\n",
    "    acc = test()[1]\n",
    "\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print('Load {}th epoch'.format(best_epoch))\n",
    "print(\"Val\",\"acc.:{:.1f}\".format(acc*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f005bd-f8ab-414d-aa7d-49979367005f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
