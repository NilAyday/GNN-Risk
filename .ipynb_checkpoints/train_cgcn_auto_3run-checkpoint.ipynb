{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62169ce6-d3ff-486e-8af5-4fc9a5c00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *\n",
    "import pickle\n",
    "import itertools\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ddbba5-f6a5-4367-837b-bcdea631a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708])\n",
      "torch.Size([140])\n",
      "torch.Size([500])\n",
      "torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayday\\Desktop\\Master_Thesis\\experiment\\utils.py:87: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n"
     ]
    }
   ],
   "source": [
    "data='cora'\n",
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation(data)\n",
    "#splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "#adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data(data,splitstr)\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(idx_train.shape)\n",
    "print(idx_val.shape)\n",
    "print(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f516b9ec-672b-4a67-99b1-bbf1323a7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42522538-1af7-4041-894c-3100f095ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=features.shape[0]\n",
    "feature_size=features.shape[1]\n",
    "num_classes = len(torch.unique(labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e25c24-4159-4e80-92d0-987042226f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee82cd-1ba7-4682-8c7f-2a8ff358a71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf9e80-fea2-443e-93b7-ded05b3e327d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9578-d717-4873-a300-cfd4d01f74b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6477916-3c0a-42a5-925c-7ca5bd3c39e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[43mAH\u001b[49m,A,X]\n\u001b[0;32m      2\u001b[0m results\n\u001b[0;32m      3\u001b[0m combinations\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AH' is not defined"
     ]
    }
   ],
   "source": [
    "[AH,A,X]\n",
    "results\n",
    "combinations\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'accuracy': 0.792}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32], 'accuracy': 0.778}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'accuracy': 0.786}\n",
    "\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features+n+nfeat, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee6485-6a08-4187-aa06-c698c959e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[H-AH, A, X]\n",
    "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'accuracy': 0.64}\n",
    "results_1\n",
    "intersting all the good acc without hidden layer\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features+n+nfeat, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        #support = torch.cat((torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        #output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "        support = torch.cat((input - torch.mm(adj.to_dense(), input),adj.to_dense(),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677f569-494a-44a2-9504-74dd7b86ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AH+H\n",
    "skip connection\n",
    "results_2\n",
    "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8200000000000001}\n",
    "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'accuracy': 0.81}\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        support = torch.mm(adj.to_dense(), input) + input\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17ca7a-f77a-4d85-89d2-2eb32b47a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,AH+H]\n",
    "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'accuracy': 0.812}\n",
    "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'accuracy': 0.81}\n",
    "results3\n",
    "'''\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(nfeat+in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((x,torch.mm(adj.to_dense(), input) + input),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ab8d3f-5aaa-48b6-9a9d-3bc67037110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[AH,X]\n",
    "\n",
    "#{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'accuracy': 0.8180000000000001}\n",
    "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8113333333333334, 'std_accuracy': 0.011813363431112911}\n",
    "class my_GraphConvolution(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, in_features, out_features,nfeat, bias=True):\n",
    "        super(my_GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(nfeat+in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj,x):\n",
    "        \n",
    "        \n",
    "        #support = torch.cat((input-torch.mm(adj.to_dense(), input), adj.to_dense()),1)\n",
    "        \n",
    "        support = torch.cat((torch.mm(adj.to_dense(), input),x),1)\n",
    "        output = torch.mm(support, self.weight)\n",
    "\n",
    "        #output= torch.mm(torch.mm(adj.to_dense(), input) + input, self.weight)\n",
    "\n",
    "       \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class my_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid_list, nclass, dropout):\n",
    "        super(my_GCN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        if nhid_list:\n",
    "            # Input layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nhid_list[0],nfeat))\n",
    "            \n",
    "            # Hidden layers\n",
    "            for i in range(1, len(nhid_list)):\n",
    "                self.layers.append(my_GraphConvolution(nhid_list[i-1], nhid_list[i],nfeat))\n",
    "            \n",
    "            # Output layer\n",
    "            self.layers.append(my_GraphConvolution(nhid_list[-1], nclass,nfeat))\n",
    "        else:\n",
    "            # Single output layer\n",
    "            self.layers.append(my_GraphConvolution(int(round(nfeat)), nclass,nfeat))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = x.detach().requires_grad_()\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            h = F.relu(layer(h, adj,x))\n",
    "            h = F.dropout(h, self.dropout, training=self.training)\n",
    "        \n",
    "        h = self.layers[-1](h, adj,x)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6a75c7-f2cd-4fc6-8874-0b5b0c373450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already run combination: (0.05, 0.0005, 0.5, ())\n",
      "Skipping already run combination: (0.05, 0.0005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, ())\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.05, 0.0005, 0.3, (512, 1024, 512))\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, ())\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.05, 0.005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, ())\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.05, 0.005, 0.3, (512, 1024, 512))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, ())\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, ())\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.01, 0.0005, 0.3, (512, 1024, 512))\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, ())\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.01, 0.005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, ())\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.01, 0.005, 0.3, (512, 1024, 512))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, ())\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, ())\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.005, 0.0005, 0.3, (512, 1024, 512))\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, ())\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, (256, 512))\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, (16, 32, 16))\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, (64, 128, 64))\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, (128, 256, 128))\n",
      "Skipping already run combination: (0.005, 0.005, 0.5, (512, 1024, 512))\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, ())\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, (256, 512))\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, (16, 32, 16))\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, (64, 128, 64))\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, (128, 256, 128))\n",
      "Skipping already run combination: (0.005, 0.005, 0.3, (512, 1024, 512))\n",
      "Hyperparameters and accuracies sorted by mean accuracy:\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8113333333333334, 'std_accuracy': 0.011813363431112911}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8106666666666668, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.81, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.81, 'std_accuracy': 0.002828427124746193}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.81, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.8093333333333333, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8093333333333333, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8080000000000002, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8080000000000002, 'std_accuracy': 0.014966629547095779}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8080000000000002, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8080000000000002, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.8073333333333333, 'std_accuracy': 0.009285592184789422}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8066666666666666, 'std_accuracy': 0.011469767022723513}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.8066666666666666, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8066666666666666, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.806, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.806, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8053333333333335, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8053333333333335, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8053333333333335, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8053333333333335, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8046666666666668, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8046666666666668, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8046666666666668, 'std_accuracy': 0.0131993265821489}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8046666666666668, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8046666666666668, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.014236104336041762}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.014142135623730965}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8039999999999999, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.006798692684790385}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8033333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.8026666666666668, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.8026666666666668, 'std_accuracy': 0.019344824171395894}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8026666666666668, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8026666666666668, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8026666666666668, 'std_accuracy': 0.013597385369580772}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.802, 'std_accuracy': 0.012328828005937964}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.802, 'std_accuracy': 0.002828427124746193}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.802, 'std_accuracy': 0.011430952132988174}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.802, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.802, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.8013333333333333, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.8013333333333333, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8013333333333333, 'std_accuracy': 0.012256517540566834}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.8013333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8006666666666667, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.0065319726474218145}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.8000000000000002, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.01651934892448517}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.011813363431112911}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.014267289706021811}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7993333333333333, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7986666666666666, 'std_accuracy': 0.00805536398239639}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7986666666666666, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7986666666666666, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7986666666666666, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7986666666666666, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.798, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.798, 'std_accuracy': 0.014966629547095779}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.798, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.798, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.798, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.798, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7973333333333334, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.006798692684790386}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7966666666666667, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7959999999999999, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.011115554667022054}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.012472191289246483}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7953333333333333, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.010370899457402705}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.010370899457402705}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.015084944665313026}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7946666666666667, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.0028284271247461927}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.010708252269472682}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.794, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.012754084313139338}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.794, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.794, 'std_accuracy': 0.0028284271247461927}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7933333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7933333333333333, 'std_accuracy': 0.01472714802291636}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7933333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7933333333333333, 'std_accuracy': 0.005249338582674546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7933333333333333, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.011585431464655188}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.021746008573733475}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.0131993265821489}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7926666666666667, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.014236104336041762}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.013063945294843629}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7920000000000001, 'std_accuracy': 0.019798989873223347}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.012472191289246483}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.013695092389449437}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.018571184369578844}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7913333333333333, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.014817407180595259}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.015434449203720314}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.00805536398239639}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.007363574011458181}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.01472714802291636}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7906666666666666, 'std_accuracy': 0.016110727964792775}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.79, 'std_accuracy': 0.014514360704718175}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.79, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.79, 'std_accuracy': 0.014142135623730963}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.79, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.79, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.016438437341250618}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.00805536398239639}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.012256517540566836}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7893333333333334, 'std_accuracy': 0.011469767022723513}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7886666666666667, 'std_accuracy': 0.018571184369578844}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7886666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7886666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7886666666666667, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7886666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.011313708498984769}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.018402898322456365}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7879999999999999, 'std_accuracy': 0.014966629547095779}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.012036980056845203}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.01388844443733312}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.006798692684790385}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7873333333333333, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.011813363431112911}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7866666666666667, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.786, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.786, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.786, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.786, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.786, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7853333333333333, 'std_accuracy': 0.011469767022723513}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7853333333333333, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7846666666666667, 'std_accuracy': 0.017461067804945076}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7846666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7846666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.012328828005937964}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.026127890589687258}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.01796292478040999}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.024055491403558307}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.008485281374238578}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.0065319726474218145}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.011430952132988174}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7840000000000001, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.017461067804945076}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.01791337179005922}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.009843215373488944}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.017461067804945076}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.00736357401145818}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7833333333333333, 'std_accuracy': 0.013888444437333117}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7826666666666666, 'std_accuracy': 0.009285592184789422}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7826666666666666, 'std_accuracy': 0.016438437341250618}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7826666666666666, 'std_accuracy': 0.006798692684790386}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7826666666666666, 'std_accuracy': 0.014817407180595259}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.782, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [256, 512], 'mean_accuracy': 0.782, 'std_accuracy': 0.011430952132988175}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.782, 'std_accuracy': 0.007483314773547889}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.782, 'std_accuracy': 0.008164965809277268}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.782, 'std_accuracy': 0.002828427124746193}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7813333333333334, 'std_accuracy': 0.010624918300339495}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7813333333333334, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7813333333333334, 'std_accuracy': 0.015434449203720314}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7813333333333334, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.020677416559027783}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.012256517540566834}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.017461067804945076}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7806666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.01275408431313934}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.005887840577551903}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.0065319726474218145}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.008640987597877155}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7799999999999999, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [256, 512], 'mean_accuracy': 0.7793333333333333, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [256, 512], 'mean_accuracy': 0.7793333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7793333333333333, 'std_accuracy': 0.026849374087469714}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7793333333333333, 'std_accuracy': 0.01651934892448517}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7793333333333333, 'std_accuracy': 0.004714045207910321}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.0037712361663282566}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.0131993265821489}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.009977753031397186}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.011469767022723513}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7786666666666667, 'std_accuracy': 0.0041096093353126546}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.778, 'std_accuracy': 0.021416504538945363}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.778, 'std_accuracy': 0.011775681155103806}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.778, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.778, 'std_accuracy': 0.009933109617167568}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7773333333333333, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7773333333333333, 'std_accuracy': 0.014267289706021811}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [256, 512], 'mean_accuracy': 0.7766666666666667, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7766666666666667, 'std_accuracy': 0.025315783394730056}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7766666666666667, 'std_accuracy': 0.02074179891480541}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7760000000000001, 'std_accuracy': 0.016083117442419772}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7760000000000001, 'std_accuracy': 0.009092121131323912}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7760000000000001, 'std_accuracy': 0.017204650534085267}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7753333333333333, 'std_accuracy': 0.013299958228840014}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7753333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7753333333333333, 'std_accuracy': 0.02322833518691248}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.009843215373488942}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.0131993265821489}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.02074179891480541}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.03086889840744063}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.016110727964792775}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7746666666666666, 'std_accuracy': 0.010498677165349092}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.774, 'std_accuracy': 0.02196967607104546}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7733333333333334, 'std_accuracy': 0.01517307556898807}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7733333333333334, 'std_accuracy': 0.010370899457402707}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7733333333333334, 'std_accuracy': 0.015860503004493775}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7726666666666667, 'std_accuracy': 0.012256517540566834}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7726666666666667, 'std_accuracy': 0.017307673314329575}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.011115554667022054}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.01791337179005922}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7713333333333333, 'std_accuracy': 0.015434449203720314}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.02028683207293727}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.013597385369580772}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7706666666666667, 'std_accuracy': 0.014817407180595259}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.77, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.77, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.77, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7686666666666667, 'std_accuracy': 0.018926759422104537}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7686666666666667, 'std_accuracy': 0.018061622912192106}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7686666666666667, 'std_accuracy': 0.02223110933404411}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.7680000000000001, 'std_accuracy': 0.03581433604950215}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.019136933459209783}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7673333333333333, 'std_accuracy': 0.011585431464655188}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7666666666666666, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.766, 'std_accuracy': 0.03973243846867027}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [512, 1024, 512], 'mean_accuracy': 0.766, 'std_accuracy': 0.011775681155103806}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.013299958228840015}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.009843215373488942}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7653333333333334, 'std_accuracy': 0.019482185594936627}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7646666666666667, 'std_accuracy': 0.010624918300339495}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.0028284271247461922}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.042551929059287896}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7639999999999999, 'std_accuracy': 0.017204650534085267}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7633333333333333, 'std_accuracy': 0.017461067804945076}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7626666666666667, 'std_accuracy': 0.015434449203720314}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.762, 'std_accuracy': 0.021416504538945367}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.016438437341250618}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7613333333333333, 'std_accuracy': 0.031930480039541485}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7606666666666667, 'std_accuracy': 0.017152907107024825}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7600000000000001, 'std_accuracy': 0.01766352173265571}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7593333333333333, 'std_accuracy': 0.02379542439676635}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.758, 'std_accuracy': 0.012754084313139338}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7573333333333334, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7553333333333333, 'std_accuracy': 0.005734883511361756}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.754, 'std_accuracy': 0.03253715824509984}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.754, 'std_accuracy': 0.01019803902718558}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.026599916457680027}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7533333333333333, 'std_accuracy': 0.022291004663067337}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.011115554667022054}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7526666666666667, 'std_accuracy': 0.023456816114345597}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7513333333333333, 'std_accuracy': 0.003399346342395193}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7506666666666666, 'std_accuracy': 0.008379870059984364}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7506666666666666, 'std_accuracy': 0.029318177903061387}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.75, 'std_accuracy': 0.020848661028149203}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.75, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.75, 'std_accuracy': 0.033506218328344196}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.023907228102721497}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.0260426999794995}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7493333333333334, 'std_accuracy': 0.019686430746977884}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7486666666666667, 'std_accuracy': 0.02694851057521034}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7486666666666667, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7486666666666667, 'std_accuracy': 0.007717224601860157}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7473333333333333, 'std_accuracy': 0.03511251755270321}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7453333333333333, 'std_accuracy': 0.016996731711975962}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7440000000000001, 'std_accuracy': 0.030594117081556686}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7433333333333333, 'std_accuracy': 0.02217105219775454}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.742, 'std_accuracy': 0.029393876913398162}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7413333333333334, 'std_accuracy': 0.01472714802291636}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.7413333333333334, 'std_accuracy': 0.012472191289246483}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.03209707497922857}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7393333333333333, 'std_accuracy': 0.03403266404826723}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7386666666666667, 'std_accuracy': 0.03868964834279173}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7373333333333334, 'std_accuracy': 0.025629843715654754}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7373333333333333, 'std_accuracy': 0.008219218670625309}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7366666666666667, 'std_accuracy': 0.02604269997949945}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7360000000000001, 'std_accuracy': 0.0256645020732269}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7313333333333333, 'std_accuracy': 0.024513035081133627}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7306666666666667, 'std_accuracy': 0.04382794643704959}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7280000000000001, 'std_accuracy': 0.02315167380558042}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7266666666666667, 'std_accuracy': 0.05256953067657685}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7253333333333334, 'std_accuracy': 0.03739280976634707}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.722, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7213333333333334, 'std_accuracy': 0.04080304999493161}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7200000000000001, 'std_accuracy': 0.03409789827345177}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7160000000000001, 'std_accuracy': 0.033025242870668874}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7126666666666668, 'std_accuracy': 0.02876726534718853}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7126666666666667, 'std_accuracy': 0.009977753031397146}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.7120000000000001, 'std_accuracy': 0.010198039027185543}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7073333333333333, 'std_accuracy': 0.03954182033689843}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.7060000000000001, 'std_accuracy': 0.011430952132988123}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.7020000000000001, 'std_accuracy': 0.036914315199752315}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6973333333333334, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6966666666666668, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6960000000000001, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.6953333333333332, 'std_accuracy': 0.039135093657171105}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6940000000000001, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.05, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6940000000000001, 'std_accuracy': 0.0016329931618554536}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6913333333333335, 'std_accuracy': 0.0018856180831641283}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6906666666666667, 'std_accuracy': 0.012256517540566782}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6900000000000001, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6866666666666666, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.6866666666666666, 'std_accuracy': 0.018354533197248248}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6853333333333333, 'std_accuracy': 0.004988876515698593}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.684, 'std_accuracy': 0.0}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6826666666666666, 'std_accuracy': 0.0024944382578492965}\n",
      "{'lr': 0.05, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6826666666666666, 'std_accuracy': 0.0009428090415820641}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6806666666666668, 'std_accuracy': 0.010370899457402707}\n",
      "{'lr': 0.01, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.68, 'std_accuracy': 0.00489897948556636}\n",
      "{'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6786666666666666, 'std_accuracy': 0.00805536398239639}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6786666666666666, 'std_accuracy': 0.01961858529274957}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6766666666666667, 'std_accuracy': 0.015860503004493775}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.676, 'std_accuracy': 0.0}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.676, 'std_accuracy': 0.0}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.676, 'std_accuracy': 0.0}\n",
      "{'lr': 0.05, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.676, 'std_accuracy': 0.0}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.67, 'std_accuracy': 0.015577761927397245}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6686666666666667, 'std_accuracy': 0.010624918300339493}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.668, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6673333333333334, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.664, 'std_accuracy': 0.0032659863237109073}\n",
      "{'lr': 0.01, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6626666666666666, 'std_accuracy': 0.008993825042154702}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.6613333333333333, 'std_accuracy': 0.008055363982396388}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6613333333333333, 'std_accuracy': 0.010873004286866737}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6593333333333334, 'std_accuracy': 0.012036980056845205}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.6553333333333334, 'std_accuracy': 0.040077702307171024}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.65, 'std_accuracy': 0.0200665559243899}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6486666666666667, 'std_accuracy': 0.009843215373488942}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.648, 'std_accuracy': 0.0792632743877432}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.6473333333333334, 'std_accuracy': 0.010370899457402707}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.646, 'std_accuracy': 0.02833137248116773}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.6433333333333334, 'std_accuracy': 0.0271456974286698}\n",
      "{'lr': 0.005, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6426666666666666, 'std_accuracy': 0.009568466729604892}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.642, 'std_accuracy': 0.007483314773547889}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.638, 'std_accuracy': 0.015577761927397243}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.6373333333333334, 'std_accuracy': 0.22870262108005868}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.634, 'std_accuracy': 0.005656854249492386}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.632, 'std_accuracy': 0.007118052168020881}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.628, 'std_accuracy': 0.0043204937989385775}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.6246666666666667, 'std_accuracy': 0.04828618389928485}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.624, 'std_accuracy': 0.22636843125017825}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.6233333333333334, 'std_accuracy': 0.006182412330330475}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.6226666666666667, 'std_accuracy': 0.24388157417529974}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.6213333333333334, 'std_accuracy': 0.22581605099923455}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.6173333333333334, 'std_accuracy': 0.042405450383438}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [128, 512, 128], 'mean_accuracy': 0.6166666666666667, 'std_accuracy': 0.22675880480271446}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6106666666666667, 'std_accuracy': 0.05751135153650586}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.6073333333333334, 'std_accuracy': 0.015691469727919773}\n",
      "{'lr': 0.005, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.606, 'std_accuracy': 0.20923352185217994}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.598, 'std_accuracy': 0.28428624072695935}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.5866666666666667, 'std_accuracy': 0.2804963853995667}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.586, 'std_accuracy': 0.06525846049874812}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.5840000000000001, 'std_accuracy': 0.041214884042863276}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.576, 'std_accuracy': 0.22610322126556856}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.574, 'std_accuracy': 0.20135540717845155}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.5713333333333334, 'std_accuracy': 0.05833999961909115}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5640000000000001, 'std_accuracy': 0.08485281374238572}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5640000000000001, 'std_accuracy': 0.28426747967363414}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.5619999999999999, 'std_accuracy': 0.24214045510818716}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.5606666666666668, 'std_accuracy': 0.07756860762504952}\n",
      "{'lr': 0.005, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5586666666666668, 'std_accuracy': 0.27853106748719353}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.5486666666666666, 'std_accuracy': 0.25182710118033147}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.5373333333333333, 'std_accuracy': 0.15088479784995645}\n",
      "{'lr': 0.05, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.5326666666666666, 'std_accuracy': 0.15320864495480954}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.5273333333333333, 'std_accuracy': 0.10487240925153872}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.522, 'std_accuracy': 0.16548111674750082}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.5093333333333333, 'std_accuracy': 0.14943746369486988}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.49133333333333334, 'std_accuracy': 0.17973560829420776}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.47266666666666673, 'std_accuracy': 0.23471022323045262}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.43866666666666676, 'std_accuracy': 0.19280617786321638}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.4306666666666667, 'std_accuracy': 0.0318468557666565}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.42, 'std_accuracy': 0.1830919623213064}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.4186666666666667, 'std_accuracy': 0.13610126948546644}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [128, 256, 128], 'mean_accuracy': 0.408, 'std_accuracy': 0.2828615680269532}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.38999999999999996, 'std_accuracy': 0.16332380924613127}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.38933333333333336, 'std_accuracy': 0.10658747059992038}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.3846666666666667, 'std_accuracy': 0.03184685576665648}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.36933333333333335, 'std_accuracy': 0.032714251057027466}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.36800000000000005, 'std_accuracy': 0.0693012746395524}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.36333333333333334, 'std_accuracy': 0.08492087820763253}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.35800000000000004, 'std_accuracy': 0.22801754318472955}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.3566666666666667, 'std_accuracy': 0.054094567400268787}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.3546666666666667, 'std_accuracy': 0.13549251721856165}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.34600000000000003, 'std_accuracy': 0.04245782220824176}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.3373333333333333, 'std_accuracy': 0.12545738541654516}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.33666666666666667, 'std_accuracy': 0.05760401220594119}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.33, 'std_accuracy': 0.031112698372208092}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.3186666666666667, 'std_accuracy': 0.15017619281660088}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.3153333333333333, 'std_accuracy': 0.15430993343124597}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [64, 128, 64], 'mean_accuracy': 0.2986666666666667, 'std_accuracy': 0.10515174220567573}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.29400000000000004, 'std_accuracy': 0.08574380444090407}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.28933333333333333, 'std_accuracy': 0.10847221866552846}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.2886666666666667, 'std_accuracy': 0.044131117769160975}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.2866666666666667, 'std_accuracy': 0.08488947062046165}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.26666666666666666, 'std_accuracy': 0.05076306618880393}\n",
      "{'lr': 0.005, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.26333333333333336, 'std_accuracy': 0.05771962885843563}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.242, 'std_accuracy': 0.10246300145255686}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.2326666666666667, 'std_accuracy': 0.06371464161050862}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.22733333333333336, 'std_accuracy': 0.07732758599332812}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.22333333333333336, 'std_accuracy': 0.03399346342395191}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.22266666666666668, 'std_accuracy': 0.041994708661396325}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.22066666666666668, 'std_accuracy': 0.06599663291074442}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.21866666666666668, 'std_accuracy': 0.00659966329107445}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.2026666666666667, 'std_accuracy': 0.05118159391378464}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.20199999999999999, 'std_accuracy': 0.0749933330370107}\n",
      "{'lr': 0.001, 'weight_decay': 0.0001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.19133333333333336, 'std_accuracy': 0.024567367696917704}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [], 'mean_accuracy': 0.18600000000000003, 'std_accuracy': 0.04811098280711657}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.18066666666666667, 'std_accuracy': 0.013597385369580758}\n",
      "{'lr': 0.01, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.18000000000000002, 'std_accuracy': 0.05995553908244565}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.18000000000000002, 'std_accuracy': 0.031155523854794455}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.2, 'nhid_list': [], 'mean_accuracy': 0.17733333333333334, 'std_accuracy': 0.023170862929310365}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.5, 'nhid_list': [32, 64, 32], 'mean_accuracy': 0.17, 'std_accuracy': 0.050622788017519016}\n",
      "{'lr': 0.001, 'weight_decay': 0.0005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.16733333333333333, 'std_accuracy': 0.06955733047078663}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [], 'mean_accuracy': 0.15866666666666668, 'std_accuracy': 0.012036980056845191}\n",
      "{'lr': 0.001, 'weight_decay': 0.001, 'dropout': 0.4, 'nhid_list': [], 'mean_accuracy': 0.14200000000000002, 'std_accuracy': 0.0566627449623354}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.4, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.142, 'std_accuracy': 0.01979898987322333}\n",
      "{'lr': 0.001, 'weight_decay': 0.005, 'dropout': 0.3, 'nhid_list': [16, 32, 16], 'mean_accuracy': 0.13933333333333334, 'std_accuracy': 0.008379870059984354}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define your train, validate, and test functions\n",
    "def train(model, optimizer, features, adj, labels, idx_train):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(), acc_train.item()\n",
    "\n",
    "def validate(model, features, adj, labels, idx_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(), acc_val.item()\n",
    "\n",
    "def test(model, features, adj, labels, idx_test, checkpt_file):\n",
    "    model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(), acc_test.item()\n",
    "\n",
    "def load_previous_results(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return []\n",
    "\n",
    "def save_results(file_path, results):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "# Hyperparameters\n",
    "nfeat = features.shape[1]\n",
    "nclass = num_classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hyperparams = {\n",
    "    'lr': [0.05, 0.01, 0.005, 0.001],\n",
    "    'weight_decay': [5e-4, 5e-3, 1e-4, 1e-3],\n",
    "    'dropout': [0.5, 0.3, 0.4, 0.2],\n",
    "    'nhid_list': [[], [64],[64,64],[256, 512], [16, 32, 16], [64, 128, 64], [128, 256, 128], [512, 1024, 512], [32, 64, 32], [128, 512, 128]]\n",
    "}\n",
    "\n",
    "# File paths for saving results and combinations\n",
    "results_file_path = 'results_4.pkl'\n",
    "combinations_file_path = 'combinations_4.pkl'\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# To store already run combinations\n",
    "run_combinations = set()\n",
    "\n",
    "# Load previously run combinations if available\n",
    "results = load_previous_results(results_file_path)\n",
    "for result in results:\n",
    "     run_combinations.add((result['lr'], result['weight_decay'], result['dropout'], tuple(result['nhid_list'])))\n",
    "\n",
    "for lr, weight_decay, dropout, nhid_list in itertools.product(\n",
    "    hyperparams['lr'], hyperparams['weight_decay'], hyperparams['dropout'], hyperparams['nhid_list']\n",
    "):\n",
    "    combination = (lr, weight_decay, dropout, tuple(nhid_list))\n",
    "    \n",
    "    if combination in run_combinations:\n",
    "        print(f\"Skipping already run combination: {combination}\")\n",
    "        continue\n",
    "    \n",
    "    run_combinations.add(combination)\n",
    "    \n",
    "    accuracies = []\n",
    "    for _ in range(3):  # Run each combination 3 times\n",
    "        model = my_GCN(nfeat, nhid_list, nclass, dropout)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        epochs = 100\n",
    "        patience = 10\n",
    "        best = 999999999\n",
    "        best_epoch = 0\n",
    "        acc = 0\n",
    "        t_total = time.time()\n",
    "        bad_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_tra, acc_tra = train(model, optimizer, features, adj, labels, idx_train)\n",
    "            loss_val, acc_val = validate(model, features, adj, labels, idx_val)\n",
    "            if (epoch+1) % 1 == 0: \n",
    "                pass  # You can print progress here if needed\n",
    "\n",
    "            if loss_val < best:\n",
    "                best = loss_val\n",
    "                best_epoch = epoch\n",
    "                acc = acc_val\n",
    "                bad_counter = 0\n",
    "            else:\n",
    "                bad_counter += 1\n",
    "\n",
    "            if bad_counter == patience:\n",
    "                break\n",
    "\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies)\n",
    "    \n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'dropout': dropout,\n",
    "        'nhid_list': nhid_list,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc\n",
    "    })\n",
    "\n",
    "# Sort results by mean accuracy in descending order\n",
    "results = sorted(results, key=lambda x: x['mean_accuracy'], reverse=True)\n",
    "\n",
    "print(\"Hyperparameters and accuracies sorted by mean accuracy:\")\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Save results and run_combinations for future use\n",
    "save_results(results_file_path, results)\n",
    "save_results(combinations_file_path, list(run_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f28a6-47bb-4aae-a7b3-c7b941a071e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
