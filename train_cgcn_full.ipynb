{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62169ce6-d3ff-486e-8af5-4fc9a5c00eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import uuid\n",
    "from utils import *\n",
    "from model import *\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddbba5-f6a5-4367-837b-bcdea631a5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f516b9ec-672b-4a67-99b1-bbf1323a7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaid = \"cuda\"\n",
    "device = torch.device(cudaid)\n",
    "checkpt_file = 'pretrained/'+uuid.uuid4().hex+'.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42522538-1af7-4041-894c-3100f095ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf9578-d717-4873-a300-cfd4d01f74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model,optimizer,features,labels,adj,idx_train):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate_step(model,features,labels,adj,idx_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test_step(model,features,labels,adj,idx_test):\n",
    "    model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "    \n",
    "\n",
    "def train(datastr,splitstr):\n",
    "    splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(0)+'.npz'\n",
    "    adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data(data,splitstr)\n",
    "    \n",
    "    features = features.to(device)\n",
    "    adj = adj.to(device)\n",
    "    n=features.shape[0]\n",
    "    feature_size=features.shape[1]\n",
    "    num_classes = len(torch.unique(labels))\n",
    "    hidden_dim=16\n",
    "    dropout=0.5\n",
    "    model=my_GCN(n,feature_size,hidden_dim,num_classes,dropout)\n",
    "    #model=GCN(feature_size,hidden_dim,num_classes,dropout)\n",
    "    model=model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)\n",
    "\n",
    "    epochs=200\n",
    "    patience=10\n",
    "    test=False\n",
    "\n",
    "    bad_counter = 0\n",
    "    best = 999999999\n",
    "    for epoch in range(epochs):\n",
    "        loss_tra,acc_tra = train_step(model,optimizer,features,labels,adj,idx_train)\n",
    "        loss_val,acc_val = validate_step(model,features,labels,adj,idx_val)\n",
    "        if(epoch+1)%1 == 0: \n",
    "            print('Epoch:{:04d}'.format(epoch+1),\n",
    "                'train',\n",
    "                'loss:{:.3f}'.format(loss_tra),\n",
    "                'acc:{:.2f}'.format(acc_tra*100),\n",
    "                '| val',\n",
    "                'loss:{:.3f}'.format(loss_val),\n",
    "                'acc:{:.2f}'.format(acc_val*100))\n",
    "        if loss_val < best:\n",
    "            best = loss_val\n",
    "            torch.save(model.state_dict(), checkpt_file)\n",
    "            bad_counter = 0\n",
    "        else:\n",
    "            bad_counter += 1\n",
    "\n",
    "        if bad_counter == patience:\n",
    "            break\n",
    "    acc = test_step(model,features,labels,adj,idx_test)[1]\n",
    "\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6477916-3c0a-42a5-925c-7ca5bd3c39e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001 train loss:1.929 acc:12.97 | val loss:1.683 acc:40.94\n",
      "Epoch:0002 train loss:1.596 acc:46.93 | val loss:1.340 acc:62.35\n",
      "Epoch:0003 train loss:1.024 acc:72.74 | val loss:1.073 acc:66.95\n",
      "Epoch:0004 train loss:0.626 acc:82.83 | val loss:0.885 acc:72.49\n",
      "Epoch:0005 train loss:0.361 acc:90.91 | val loss:0.841 acc:75.02\n",
      "Epoch:0006 train loss:0.252 acc:93.98 | val loss:0.921 acc:68.17\n",
      "Epoch:0007 train loss:0.219 acc:94.74 | val loss:0.953 acc:66.10\n",
      "Epoch:0008 train loss:0.181 acc:95.93 | val loss:0.931 acc:68.36\n",
      "Epoch:0009 train loss:0.132 acc:96.87 | val loss:0.907 acc:71.64\n",
      "Epoch:0010 train loss:0.094 acc:97.93 | val loss:0.902 acc:72.58\n",
      "Epoch:0011 train loss:0.081 acc:97.99 | val loss:0.909 acc:73.05\n",
      "Epoch:0012 train loss:0.073 acc:98.18 | val loss:0.923 acc:73.15\n",
      "Epoch:0013 train loss:0.061 acc:98.43 | val loss:0.940 acc:73.05\n",
      "Epoch:0014 train loss:0.061 acc:98.31 | val loss:0.959 acc:71.74\n",
      "Epoch:0015 train loss:0.064 acc:98.75 | val loss:0.977 acc:70.89\n",
      "0 : 72.22\n",
      "Epoch:0001 train loss:1.830 acc:18.67 | val loss:1.605 acc:30.61\n",
      "Epoch:0002 train loss:1.428 acc:47.74 | val loss:1.254 acc:63.00\n",
      "Epoch:0003 train loss:0.939 acc:70.99 | val loss:1.024 acc:68.26\n",
      "Epoch:0004 train loss:0.546 acc:86.22 | val loss:0.907 acc:71.55\n",
      "Epoch:0005 train loss:0.354 acc:92.36 | val loss:0.883 acc:70.23\n",
      "Epoch:0006 train loss:0.249 acc:94.05 | val loss:0.876 acc:72.86\n",
      "Epoch:0007 train loss:0.185 acc:95.61 | val loss:0.880 acc:72.86\n",
      "Epoch:0008 train loss:0.150 acc:95.68 | val loss:0.883 acc:73.43\n",
      "Epoch:0009 train loss:0.117 acc:96.68 | val loss:0.892 acc:73.71\n",
      "Epoch:0010 train loss:0.095 acc:96.68 | val loss:0.909 acc:74.08\n",
      "Epoch:0011 train loss:0.071 acc:97.81 | val loss:0.933 acc:73.52\n",
      "Epoch:0012 train loss:0.071 acc:98.06 | val loss:0.957 acc:72.86\n",
      "Epoch:0013 train loss:0.050 acc:98.87 | val loss:0.978 acc:72.49\n",
      "Epoch:0014 train loss:0.055 acc:98.56 | val loss:0.995 acc:71.17\n",
      "Epoch:0015 train loss:0.062 acc:98.50 | val loss:1.003 acc:70.52\n",
      "Epoch:0016 train loss:0.063 acc:98.12 | val loss:1.003 acc:70.70\n",
      "1 : 70.57\n",
      "Epoch:0001 train loss:1.889 acc:15.85 | val loss:1.746 acc:27.14\n",
      "Epoch:0002 train loss:1.620 acc:33.40 | val loss:1.366 acc:58.69\n",
      "Epoch:0003 train loss:1.032 acc:69.49 | val loss:1.170 acc:65.16\n",
      "Epoch:0004 train loss:0.685 acc:81.27 | val loss:0.962 acc:69.86\n",
      "Epoch:0005 train loss:0.411 acc:90.66 | val loss:0.881 acc:72.11\n",
      "Epoch:0006 train loss:0.278 acc:94.55 | val loss:0.918 acc:67.89\n",
      "Epoch:0007 train loss:0.225 acc:95.05 | val loss:0.929 acc:67.70\n",
      "Epoch:0008 train loss:0.180 acc:95.55 | val loss:0.910 acc:71.27\n",
      "Epoch:0009 train loss:0.132 acc:96.93 | val loss:0.894 acc:72.77\n",
      "Epoch:0010 train loss:0.102 acc:97.37 | val loss:0.892 acc:73.62\n",
      "Epoch:0011 train loss:0.088 acc:97.43 | val loss:0.901 acc:73.90\n",
      "Epoch:0012 train loss:0.070 acc:98.31 | val loss:0.915 acc:73.99\n",
      "Epoch:0013 train loss:0.070 acc:98.37 | val loss:0.931 acc:73.80\n",
      "Epoch:0014 train loss:0.065 acc:98.43 | val loss:0.948 acc:73.43\n",
      "Epoch:0015 train loss:0.061 acc:98.62 | val loss:0.963 acc:72.30\n",
      "2 : 71.62\n",
      "Epoch:0001 train loss:1.858 acc:17.86 | val loss:1.587 acc:53.15\n",
      "Epoch:0002 train loss:1.452 acc:54.51 | val loss:1.253 acc:62.63\n",
      "Epoch:0003 train loss:0.955 acc:74.44 | val loss:0.900 acc:75.40\n",
      "Epoch:0004 train loss:0.482 acc:88.91 | val loss:0.862 acc:73.05\n",
      "Epoch:0005 train loss:0.335 acc:92.61 | val loss:0.928 acc:67.51\n",
      "Epoch:0006 train loss:0.256 acc:94.36 | val loss:0.874 acc:70.99\n",
      "Epoch:0007 train loss:0.174 acc:96.05 | val loss:0.835 acc:73.71\n",
      "Epoch:0008 train loss:0.120 acc:96.68 | val loss:0.845 acc:75.02\n",
      "Epoch:0009 train loss:0.092 acc:97.12 | val loss:0.876 acc:74.18\n",
      "Epoch:0010 train loss:0.081 acc:97.49 | val loss:0.907 acc:74.08\n",
      "Epoch:0011 train loss:0.081 acc:97.06 | val loss:0.930 acc:73.62\n",
      "Epoch:0012 train loss:0.063 acc:97.93 | val loss:0.946 acc:73.15\n",
      "Epoch:0013 train loss:0.056 acc:98.75 | val loss:0.962 acc:72.39\n",
      "Epoch:0014 train loss:0.054 acc:98.50 | val loss:0.979 acc:71.46\n",
      "Epoch:0015 train loss:0.061 acc:98.50 | val loss:0.996 acc:70.33\n",
      "Epoch:0016 train loss:0.062 acc:98.75 | val loss:1.007 acc:70.05\n",
      "Epoch:0017 train loss:0.066 acc:98.81 | val loss:1.006 acc:70.05\n",
      "3 : 72.22\n",
      "Epoch:0001 train loss:1.843 acc:17.67 | val loss:1.757 acc:40.19\n",
      "Epoch:0002 train loss:1.631 acc:44.67 | val loss:1.266 acc:57.09\n",
      "Epoch:0003 train loss:0.897 acc:69.99 | val loss:0.997 acc:67.70\n",
      "Epoch:0004 train loss:0.510 acc:88.16 | val loss:0.995 acc:65.82\n",
      "Epoch:0005 train loss:0.383 acc:91.17 | val loss:0.913 acc:70.61\n",
      "Epoch:0006 train loss:0.261 acc:94.05 | val loss:0.845 acc:73.15\n",
      "Epoch:0007 train loss:0.170 acc:95.30 | val loss:0.825 acc:74.93\n",
      "Epoch:0008 train loss:0.124 acc:96.80 | val loss:0.839 acc:74.93\n",
      "Epoch:0009 train loss:0.108 acc:96.80 | val loss:0.867 acc:74.84\n",
      "Epoch:0010 train loss:0.095 acc:97.18 | val loss:0.894 acc:74.27\n",
      "Epoch:0011 train loss:0.083 acc:97.62 | val loss:0.914 acc:74.55\n",
      "Epoch:0012 train loss:0.066 acc:98.43 | val loss:0.931 acc:74.18\n",
      "Epoch:0013 train loss:0.058 acc:98.43 | val loss:0.947 acc:73.05\n",
      "Epoch:0014 train loss:0.050 acc:99.00 | val loss:0.964 acc:72.30\n",
      "Epoch:0015 train loss:0.051 acc:99.19 | val loss:0.981 acc:71.08\n",
      "Epoch:0016 train loss:0.055 acc:98.93 | val loss:0.995 acc:70.70\n",
      "Epoch:0017 train loss:0.060 acc:98.93 | val loss:1.002 acc:70.70\n",
      "4 : 72.67\n",
      "Epoch:0001 train loss:1.907 acc:15.79 | val loss:1.701 acc:35.21\n",
      "Epoch:0002 train loss:1.573 acc:42.23 | val loss:1.315 acc:61.41\n",
      "Epoch:0003 train loss:1.011 acc:71.80 | val loss:1.066 acc:66.38\n",
      "Epoch:0004 train loss:0.620 acc:82.71 | val loss:0.880 acc:74.08\n",
      "Epoch:0005 train loss:0.360 acc:92.04 | val loss:0.879 acc:72.11\n",
      "Epoch:0006 train loss:0.271 acc:93.61 | val loss:0.934 acc:67.98\n",
      "Epoch:0007 train loss:0.234 acc:93.67 | val loss:0.916 acc:68.54\n",
      "Epoch:0008 train loss:0.169 acc:95.49 | val loss:0.879 acc:72.02\n",
      "Epoch:0009 train loss:0.124 acc:96.43 | val loss:0.868 acc:73.90\n",
      "Epoch:0010 train loss:0.096 acc:97.31 | val loss:0.877 acc:74.74\n",
      "Epoch:0011 train loss:0.083 acc:97.87 | val loss:0.896 acc:74.37\n",
      "Epoch:0012 train loss:0.071 acc:97.99 | val loss:0.917 acc:73.99\n",
      "Epoch:0013 train loss:0.066 acc:98.25 | val loss:0.936 acc:73.33\n",
      "Epoch:0014 train loss:0.058 acc:98.50 | val loss:0.954 acc:72.77\n",
      "Epoch:0015 train loss:0.059 acc:98.68 | val loss:0.973 acc:71.55\n",
      "Epoch:0016 train loss:0.060 acc:98.87 | val loss:0.990 acc:70.33\n",
      "Epoch:0017 train loss:0.056 acc:99.06 | val loss:1.002 acc:70.61\n",
      "Epoch:0018 train loss:0.061 acc:98.75 | val loss:1.007 acc:70.70\n",
      "Epoch:0019 train loss:0.067 acc:98.81 | val loss:1.002 acc:70.70\n",
      "5 : 71.02\n",
      "Epoch:0001 train loss:1.842 acc:19.55 | val loss:1.638 acc:33.62\n",
      "Epoch:0002 train loss:1.478 acc:44.55 | val loss:1.245 acc:61.31\n",
      "Epoch:0003 train loss:0.932 acc:72.68 | val loss:1.047 acc:65.82\n",
      "Epoch:0004 train loss:0.573 acc:85.03 | val loss:0.912 acc:72.02\n",
      "Epoch:0005 train loss:0.343 acc:92.92 | val loss:0.878 acc:70.61\n",
      "Epoch:0006 train loss:0.241 acc:94.67 | val loss:0.861 acc:72.68\n",
      "Epoch:0007 train loss:0.193 acc:94.80 | val loss:0.860 acc:73.15\n",
      "Epoch:0008 train loss:0.152 acc:95.68 | val loss:0.862 acc:74.27\n",
      "Epoch:0009 train loss:0.118 acc:96.37 | val loss:0.872 acc:74.84\n",
      "Epoch:0010 train loss:0.093 acc:97.49 | val loss:0.891 acc:74.84\n",
      "Epoch:0011 train loss:0.076 acc:97.99 | val loss:0.916 acc:74.08\n",
      "Epoch:0012 train loss:0.063 acc:98.31 | val loss:0.945 acc:72.68\n",
      "Epoch:0013 train loss:0.054 acc:98.68 | val loss:0.972 acc:71.36\n",
      "Epoch:0014 train loss:0.053 acc:98.87 | val loss:0.993 acc:70.80\n",
      "Epoch:0015 train loss:0.061 acc:98.25 | val loss:1.005 acc:70.23\n",
      "Epoch:0016 train loss:0.061 acc:98.56 | val loss:1.006 acc:70.05\n",
      "Epoch:0017 train loss:0.057 acc:98.75 | val loss:0.997 acc:70.70\n",
      "6 : 69.97\n",
      "Epoch:0001 train loss:1.851 acc:17.86 | val loss:1.670 acc:23.10\n",
      "Epoch:0002 train loss:1.549 acc:37.78 | val loss:1.375 acc:62.72\n",
      "Epoch:0003 train loss:1.069 acc:70.55 | val loss:1.135 acc:65.63\n",
      "Epoch:0004 train loss:0.668 acc:81.70 | val loss:0.885 acc:72.96\n",
      "Epoch:0005 train loss:0.358 acc:91.17 | val loss:0.848 acc:73.15\n",
      "Epoch:0006 train loss:0.246 acc:94.99 | val loss:0.949 acc:66.20\n",
      "Epoch:0007 train loss:0.219 acc:94.74 | val loss:0.981 acc:65.82\n",
      "Epoch:0008 train loss:0.183 acc:95.24 | val loss:0.952 acc:68.92\n",
      "Epoch:0009 train loss:0.128 acc:96.55 | val loss:0.926 acc:70.80\n",
      "Epoch:0010 train loss:0.102 acc:97.37 | val loss:0.916 acc:72.30\n",
      "Epoch:0011 train loss:0.079 acc:97.68 | val loss:0.920 acc:72.96\n",
      "Epoch:0012 train loss:0.069 acc:97.87 | val loss:0.930 acc:73.15\n",
      "Epoch:0013 train loss:0.066 acc:98.43 | val loss:0.944 acc:73.43\n",
      "Epoch:0014 train loss:0.060 acc:98.62 | val loss:0.959 acc:72.86\n",
      "Epoch:0015 train loss:0.055 acc:99.00 | val loss:0.973 acc:72.21\n",
      "7 : 70.87\n",
      "Epoch:0001 train loss:1.876 acc:15.10 | val loss:1.759 acc:49.20\n",
      "Epoch:0002 train loss:1.635 acc:49.12 | val loss:1.192 acc:69.20\n",
      "Epoch:0003 train loss:0.876 acc:80.89 | val loss:1.048 acc:64.04\n",
      "Epoch:0004 train loss:0.567 acc:84.96 | val loss:0.891 acc:73.24\n",
      "Epoch:0005 train loss:0.329 acc:93.48 | val loss:0.911 acc:68.17\n",
      "Epoch:0006 train loss:0.265 acc:94.05 | val loss:0.896 acc:70.14\n",
      "Epoch:0007 train loss:0.191 acc:95.30 | val loss:0.861 acc:73.52\n",
      "Epoch:0008 train loss:0.140 acc:96.49 | val loss:0.852 acc:74.46\n",
      "Epoch:0009 train loss:0.102 acc:97.37 | val loss:0.868 acc:75.49\n",
      "Epoch:0010 train loss:0.082 acc:97.62 | val loss:0.897 acc:74.55\n",
      "Epoch:0011 train loss:0.081 acc:97.87 | val loss:0.926 acc:73.43\n",
      "Epoch:0012 train loss:0.070 acc:98.06 | val loss:0.954 acc:73.24\n",
      "Epoch:0013 train loss:0.061 acc:98.37 | val loss:0.978 acc:72.21\n",
      "Epoch:0014 train loss:0.069 acc:97.81 | val loss:0.999 acc:71.92\n",
      "Epoch:0015 train loss:0.051 acc:99.12 | val loss:1.017 acc:70.70\n",
      "Epoch:0016 train loss:0.058 acc:98.87 | val loss:1.029 acc:70.42\n",
      "Epoch:0017 train loss:0.071 acc:98.43 | val loss:1.032 acc:70.14\n",
      "Epoch:0018 train loss:0.064 acc:98.93 | val loss:1.023 acc:70.52\n",
      "8 : 72.22\n",
      "Epoch:0001 train loss:1.848 acc:17.86 | val loss:1.846 acc:23.94\n",
      "Epoch:0002 train loss:1.693 acc:33.46 | val loss:1.366 acc:51.74\n",
      "Epoch:0003 train loss:1.044 acc:65.04 | val loss:1.208 acc:61.69\n",
      "Epoch:0004 train loss:0.705 acc:77.32 | val loss:1.052 acc:64.13\n",
      "Epoch:0005 train loss:0.440 acc:87.78 | val loss:0.956 acc:68.26\n",
      "Epoch:0006 train loss:0.295 acc:92.98 | val loss:0.921 acc:68.45\n",
      "Epoch:0007 train loss:0.222 acc:94.67 | val loss:0.888 acc:72.02\n",
      "Epoch:0008 train loss:0.161 acc:95.49 | val loss:0.875 acc:73.33\n",
      "Epoch:0009 train loss:0.135 acc:96.43 | val loss:0.876 acc:74.74\n",
      "Epoch:0010 train loss:0.110 acc:96.62 | val loss:0.882 acc:74.93\n",
      "Epoch:0011 train loss:0.089 acc:97.24 | val loss:0.892 acc:75.31\n",
      "Epoch:0012 train loss:0.077 acc:97.62 | val loss:0.903 acc:74.93\n",
      "Epoch:0013 train loss:0.067 acc:98.62 | val loss:0.914 acc:74.46\n",
      "Epoch:0014 train loss:0.061 acc:98.81 | val loss:0.927 acc:73.90\n",
      "Epoch:0015 train loss:0.066 acc:98.18 | val loss:0.943 acc:73.24\n",
      "Epoch:0016 train loss:0.059 acc:99.12 | val loss:0.960 acc:73.05\n",
      "Epoch:0017 train loss:0.054 acc:99.19 | val loss:0.978 acc:72.02\n",
      "Epoch:0018 train loss:0.066 acc:98.75 | val loss:0.993 acc:70.61\n",
      "9 : 72.52\n",
      "Train cost: 64.0808s\n",
      "Test acc.:71.59\n"
     ]
    }
   ],
   "source": [
    "t_total = time.time()\n",
    "acc_list = []\n",
    "#citeseer, cora\n",
    "data='citeseer'\n",
    "for i in range(10):\n",
    "    datastr = data\n",
    "    splitstr = 'splits/'+data+'_split_0.6_0.2_'+str(i)+'.npz'\n",
    "    acc_list.append(train(datastr,splitstr))\n",
    "    print(i,\": {:.2f}\".format(acc_list[-1]))\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print(\"Test acc.:{:.2f}\".format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f28a6-47bb-4aae-a7b3-c7b941a071e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(adj.to_dense().shape)\n",
    "        print(support.shape)\n",
    "        print(output.shape)\n",
    "\n",
    "\n",
    "torch.Size([2708, 2708]) adj\n",
    "torch.Size([2708, 16])  support= input x weight\n",
    "torch.Size([2708, 2724])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
